scrapy框架的工作原理
    Scrapy Engin（引擎）：scrapy框架的核心部分，负责在spider和item pipeline、Downloader、scheduler中间通信、传递数据等
    Spider（爬虫）：发送需要爬取的连接给引擎，最后引擎把其它模块请求回来的数据再发送给爬虫，爬虫就去解析想要的数据。
    Scheduler（调度器）：负责接收引擎发送过来的请求，并按照一定的方式进行排列和整理，负责调度请求的顺序等。
    Downloader（下载器）：负责接收引擎过来的下载请求，然后去网络上下载队形的数据再交给引擎。
    Item Pipeline（管道）：负责将爬虫传递过来的数据进行保存
    Downloader Middlewares（下载中间件）：可以扩展下载器和引擎之间通信功能的中间件
    Spider Middlewares（Spider中间件）：可以扩展引擎和爬虫之间通信功能的中间件


创建scrapy框架流程：
    进入到想要创建的目录下
    1、输入：scrapy startproject 项目名  ——创建项目
    2、创建爬虫模板：scrapy genspider 爬虫名 域名  如：scrapy genspider qustory xbiquge.la   ——创建爬虫
    3、编写爬虫代码
    4、编写pipeline
        ·yield的三种数据提交方式
            yield{} 字典      推送给pipeline
            yield item 对象   推送给pipeline
            yield scrap.Request() Request对象，推送给调度器
    5、数据存储


scrapy提取数据的方法
xpath()：返回选择器列表，它代表由指定的xpath表达式参数选择的节点
css()：返回选择器列表，它代表由指定css表达式作为参数所选择的节点
re():返回Unicode字符串列表，当正则表达式被赋予作为参数时提取
extract():返回一个Unicode字符串以及所选择的数据
extract_first():返回第一个Unicode字符串以及所选择的数据